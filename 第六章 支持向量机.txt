SVM是一个二元分类算法，线性分类和非线性分类都支持。经过演进，现在也可以支持多元分类，同时经过扩展，也能应用于回归问题。那些离超平面很近的点，这些点很容易被误分类。如果我们可以让离超平面比较近的点尽可能的远离超平面，那么我们的分类效果会好有一些。SVM的思想起源正起于此。
SVM的思想：SVM的模型是让所有点到超平面的距离大于一定的距离，也就是所有的分类点要在各自类别的支持向量两边。
具体推导过程参考：http://www.cnblogs.com/pinard/p/6097604.html
SVM算法的过程：
输入是m个样本（x1，y1），（x2，y2），...，（xm，ym），其中x为m维特征向量，y为二元输出
输出是分离超平面的参数w*和b*和分类决策函数
具体过程：
1、选择适当的核函数K（x，z）和一个惩罚系数C>0，构造约束优化问题
2、用SMO算法求出最小时候、对应的a向量的值a*向量
3、找出所有的S个支持向量，即满足0<a<C对应的样本（x，y），计算出每个支持向量（x，y）对应的b*，所用的b*对应的平均值就是最终的b*

错误率（error rate）：分类错误的样本数占样本总数的比例，E=a/m
精度（accuracy）：1-E
误差（error）：学习器的实际预测输出与样本是真实输出之间的差异
训练误差（training error）：学习器在训练集上的误差
泛化误差（generalization error）：学习器在新样本的误差
过拟合（overfitting）：学习器把训练样本学得“太好”了，导致泛化性能的下降
欠拟合（unoverfitting）：学习器对于训练样本尚未学好
过拟合的原因：最常见的的情况就是由于学习能力过于强大，以至于把训练样本所包含的不太一般的特性都学习了；
针对过拟合的措施：
进行交叉验证法（k-fold交叉验证），先将数据集D划分为k个大小相似的互斥子集，每个子集Di保持数据分布的一致性，都要尽可能保持数据分布的一致性，然后每次用k-1个子集作为训练集，余下的那个梓集作为测试集，这样子就可获得k组训练/测试集，从而可进行k次训练和测试，最终返回的是k个测试结果的均值
欠拟合：学习器的学习能力低下
针对欠拟合的措施：
例如：决策树学习中扩展分支，在神经网络学习中增加训练轮数等等
评估方法：
将样本集分为训练集合测试集，训练集和测试集尽可能互斥
性能度量：
分类结果混淆矩阵：TP(真正例）+FP(假正例）+TN(真反例）+FN(假反例）
准确率（precision）：TP/(TP+FP)
召回率（recall）:TP/(TP+FN)是R
P-R曲线：横坐标值P，纵坐标
F1=2*P*R/(P+R)
Fn=(1+n^2)*P*R/(n^2)P+R
ROC曲线的横轴是假正例率（FPR=FP/FP+TN），纵轴是真正例率（TPR=TP/TP+FN）
AUC（Area under ROC Curve）：AUC考虑的是样本排序的质量，因此它与排序误差有紧密联系



决策树（分而治之）：自顶向下的分类递归的过程，结果是产生一颗泛化能力很强的树
决策树的划分：
信息：度量样本集合纯度最常用的一种指标
Pk：假定当前样本集合D中第k类样本所占的比例为Pk
1、信息增益：ID3算法，
2、信息增益率：C4.5算法，
3、基尼系数：CART算法，基尼系数：1减去所有类中所占比例的平方（1-P1^2-......-Pk^2）
剪枝处理是决策树中为了防止过拟合的主要手段，主要有预剪枝和后剪枝
预剪枝：指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前的结点标记为叶结点；
后剪枝：先从训练集生成一棵完整的决策树，然后自底向上地对非叶节点进行考察，若将该结点对应的子树替换为叶结点能提高决策树的泛化性能，则将该子树替换成叶结点。
连续变量离散化&缺失值处理：决策树中需要对连续变量离散化处理，决策树中有自己处理缺失值大方法
